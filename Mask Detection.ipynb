{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9ZVy5rHz9WrU"},"outputs":[],"source":["#Importing Libraries\n","import cv2\n","import os\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4HqFP3ZW9Wrj"},"outputs":[],"source":["# Defining Variables and Setting path\n","images = []\n","targets = []"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1N3iASDj9Wrl"},"outputs":[],"source":["# {with_mask : 0, without_mask : 1 (Viceversa)} - 2 Diffetent Outputs\n","prefix_dir_without_mask = 'Dataset/without_mask/'\n","prefix_dir_with_mask = 'Dataset/with_mask/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qqaaGLt9Wrm"},"outputs":[],"source":["# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n","content = os.listdir(prefix_dir_without_mask)\n","for image in tqdm(content):\n","    try:\n","        image_path = prefix_dir_without_mask + image\n","        image = cv2.imread(image_path)\n","        image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        resized_image = cv2.resize(image_grey, (100, 100))\n","        images.append(resized_image)\n","        targets.append(1)\n","    except Exception as e:\n","        print(\"Exception occured as \",e)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uj58EiNv9Wrn","outputId":"5c1c51f3-8383-4a77-fbca-2d84f711854e"},"outputs":[],"source":["len(images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OK_w-ooe9Wrp","outputId":"eaf856a6-92f0-4d2a-daa5-99ecd4c65247"},"outputs":[],"source":["content = os.listdir(prefix_dir_with_mask)\n","for image in tqdm(content):\n","    try:\n","        image_path = prefix_dir_with_mask + image\n","        image = cv2.imread(image_path)\n","        image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        resized_image = cv2.resize(image_grey, (100, 100))\n","        images.append(resized_image)\n","        targets.append(0)\n","    except Exception as e:\n","        print(\"Exception occured as \",e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRZzR8pv9Wrr","outputId":"35acf790-064b-4cf8-9aff-84b914ebc8aa"},"outputs":[],"source":["len(images), len(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwjxEvcQ9Wrt"},"outputs":[],"source":["# Normalization\n","images = np.array(images)/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLpU67_V9Wrv","outputId":"1febbe3e-8ed4-4cd7-e8fe-038da3357486"},"outputs":[],"source":["images.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8s9DOgEu9Wrw"},"outputs":[],"source":["images = np.resize(images, (7553, 100, 100, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYrkVsyN9Wry"},"outputs":[],"source":["# Converting To Binary Class Matrix\n","targets = np_utils.to_categorical(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtYyfdm99Wr0"},"outputs":[],"source":["# Defining list variable for training \n","X_train, X_test, Y_train, Y_test = train_test_split(images, targets, test_size=0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"et_u2LEb9Wr2"},"outputs":[],"source":["# Creating Sequential model and Layers\n","model = Sequential()\n","\n","model.add(Conv2D(200, (3,3), input_shape=(100, 100, 1)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","\n","model.add(Conv2D(100, (3,3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Dropout(0.4))\n","model.add(Flatten())\n","\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(2, activation='softmax'))\n","\n","# Compiling Model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmj3WitR9Wr3","outputId":"746d6f75-75f9-4acc-e7a0-460c3758724b"},"outputs":[],"source":["# Saving Model For Future Use\n","cp = ModelCheckpoint('model-best', verbose=0, save_best_only=True)\n","# Training Model\n","model.fit(X_train, Y_train, epochs = 15,  callbacks=[cp], validation_split=0.2)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CwEGk70M9Wr5"},"outputs":[],"source":["# Loading Model\n","model = load_model('model-007.model')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6B-URj9o9Wr6"},"outputs":[],"source":["# For Face Detection\n","face_detect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"r_QdXqT_9Wr6","outputId":"638528f1-b58b-4410-e10a-1e470298a7fa"},"outputs":[],"source":["# Capturing Video\n","source = cv2.VideoCapture(0)\n","\n","while 1:\n","    not_to_use, image = source.read()\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    faces = face_detect.detectMultiScale(gray, 1.5,5)\n","    for (x, y, w, h) in faces:\n","        face_roi = gray[y:y+w, x:x+w]\n","        resized_face = cv2.resize(face_roi, (100, 100))\n","        normalized_Face = resized_face/255\n","        reshaped_face = np.reshape(normalized_Face, (1, 100, 100, 1))\n","        result = model.predict(reshaped_face)[0]\n","        # print(\"Probabilities : \",result)\n","\n","        # Using 2 Outcomes as per definition - Mask_\n","        if result[0] > result[1]:\n","            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) \n","            cv2.putText(image, \"Safe\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","        \n","\n","        if result[1] > result[0]:\n","            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n","            cv2.putText(image, \"Not Safe\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","            \n","    cv2.imshow('Project', image)\n","    key = cv2.waitKey(1)\n","    if key == 27:\n","        break\n","        \n","cv2.destroyAllWindows()\n","source.release()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"Untitled.ipynb","provenance":[]},"interpreter":{"hash":"11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"},"kernelspec":{"display_name":"Python 3.9.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
